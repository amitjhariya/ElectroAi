[[["8b09e4e1-9241-43a5-bc39-d4d0108431c0",{"pageContent":"Research and Applications\nBioLORD-2023: semantic textual representations fusing \nlarge language models and clinical knowledge graph \ninsights\nFranc ̧ois Remy , Msc\n1\n�\n, Kris Demuynck \n, PhD\n1\n, Thomas Demeester , PhD\n1\n1\nInternet and Data Science Lab, imec, Ghent University, Ghent, Belgium\n�\nCorresponding author: Franc ̧ois Remy, Msc, Internet and Data Science Lab, imec, Ghent University, Ghent, Belgium (francois.remy@ugent.be)\nAbstract \nObjective: In this study, we investigate the potential of large language models (LLMs) to complement biomedical knowledge graphs in the \ntraining of semantic models for the biomedical and clinical domains.\nMaterials and Methods: Drawing on the wealth of the Unified Medical Language System knowledge graph and harnessing cutting-edge \nLLMs, we propose a new state-of-the-art approach for obtaining high-fidelity representations of biomedical concepts and sentences, consisting","metadata":{"loc":{"lines":{"from":1,"to":21}}}}],["bae2cbd2-8c31-4c2f-9e51-07ba017ba271",{"pageContent":"LLMs, we propose a new state-of-the-art approach for obtaining high-fidelity representations of biomedical concepts and sentences, consisting \nof 3 steps: an improved contrastive learning phase, a novel self-distillation phase, and a weight averaging phase.\nResults: Through rigorous evaluations of diverse downstream tasks, we demonstrate consistent and substantial improvements over the pre-\nvious state of the art for semantic textual similarity (STS), biomedical concept representation (BCR), and clinically named entity linking, across \n15þdatasets. Besides our new state-of-the-art biomedical model for English, we also distill and release a multilingual model compatible with \n50þlanguages and finetuned on 7 European languages.\nDiscussion: Many clinical pipelines can benefit from our latest models. Our new multilingual model enables a range of languages to benefit","metadata":{"loc":{"lines":{"from":21,"to":27}}}}],["daa7b584-b1e4-467e-a2e8-bdd832aef1bb",{"pageContent":"50þlanguages and finetuned on 7 European languages.\nDiscussion: Many clinical pipelines can benefit from our latest models. Our new multilingual model enables a range of languages to benefit \nfrom our advancements in biomedical semantic representation learning, opening a new avenue for bioinformatics researchers around the world. \nAs a result, we hope to see BioLORD-2023 becoming a precious tool for future biomedical applications.\nConclusion: In this article, we introduced BioLORD-2023, a state-of-the-art model for STS and BCR designed for the clinical domain.\nKey words: natural language processing; machine learning; knowledge bases; biological ontologies; semantics. \nIntroduction\nClinical and biomedical natural language processing (NLP) \nrose to prominence in the last few years,\n1\ndebuting a long ser-\nies of surveys\n2–8\nhighlighting the potential and inherent chal-\nlenges of harnessing the synergies between, firstly, the reliable","metadata":{"loc":{"lines":{"from":26,"to":40}}}}],["7f9c62f8-e11f-4c14-ac82-a2fd99b05660",{"pageContent":"rose to prominence in the last few years,\n1\ndebuting a long ser-\nies of surveys\n2–8\nhighlighting the potential and inherent chal-\nlenges of harnessing the synergies between, firstly, the reliable \ninsights originating from biomedical knowledge graphs \n(BKGs) and, secondly, the impressive generalization capabil-\nities of  cutting-edge deep learning techniques, specifically \nlarge language models (LLMs).\nSuch an  insight fusion could have an  immense impact \nacross a  wide range of  applications, encompassing clinical \ncase summarization, clinical decision support, patient diagno-\nsis  and  triage, pharmacovigilance, disease subtyping, drug \ndiscovery, as well as help researchers build more explainable \nartificial intelligence (AI) systems.\nIn this work, we extend the line of work initiated by BioSyn,\n9\nSapBERT,\n10\nand  BioLORD\n11\nby  integrating knowledge graph \ninformation during and after the pretraining of semantic bidirec-\ntional language models.\n12","metadata":{"loc":{"lines":{"from":34,"to":60}}}}],["9213c17b-a9b1-445c-ba8a-38744ee7679d",{"pageContent":"9\nSapBERT,\n10\nand  BioLORD\n11\nby  integrating knowledge graph \ninformation during and after the pretraining of semantic bidirec-\ntional language models.\n12\nThese bidirectional models form a cor-\nnerstone of  the  modern retrieval-augmented generation (RAG) \npipeline,\n13,14\nwhich is critical in most applications of LLMs in a \nreal-world setting (both to enable LLMs to access accurate and \nup-to-date data before writing their answers, but also because it \nmakes tracing and combating erroneous answers more tractable).\nThis article introduces several novel contributions to this exist-\ning body of work, aiming: firstly, at broadening the biomedical \nexpertise of semantic models, secondly, at reducing the trade-off \nbetween the  biomedical knowledge and  the  general language \nunderstanding of finetuned models, and thirdly at enabling more \nlanguages to benefit from the obtained improvements.\nTo  this  end, we  present in  this  article a  new model,","metadata":{"loc":{"lines":{"from":52,"to":75}}}}],["650aa42c-5fd8-43b5-9970-94cb832a707e",{"pageContent":"understanding of finetuned models, and thirdly at enabling more \nlanguages to benefit from the obtained improvements.\nTo  this  end, we  present in  this  article a  new model, \nBioLORD-2023, which builds upon the achievements of the \noriginal BioLORD model\n11\nbut  has  novel characteristics, \nsuch as an improved training strategy and an updated train-\ning  corpus. The original BioLORD will henceforth be \nreferred to  as  BioLORD-2022, and  compared against the \nnew BioLORD-2023, to avoid confusion.\nThe first contribution of  BioLORD-2023 concerns the \nusage of OpenAI LLMs\n15\nfor converting into text the infor-\nmation contained in biomedical ontologies and their knowl-\nedge graphs,\n16,17\na task where LLM’s language fluency and \nlatent knowledge of biomedical matters proved useful. This is \nimportant, as only 5% of clinical concepts possess human- \nwritten definitions in  large biomedical meta-thesauri.\n11,16\nFortunately, modern LLMs prompted with knowledge graph","metadata":{"loc":{"lines":{"from":73,"to":96}}}}],["c1190eff-2b78-4e46-b018-993a66dec442",{"pageContent":"important, as only 5% of clinical concepts possess human- \nwritten definitions in  large biomedical meta-thesauri.\n11,16\nFortunately, modern LLMs prompted with knowledge graph \ninformation have been shown to  generate largely reliable, \ninsightful, and fluent definitions for a vast majority of bio-\nmedical concepts.\n18\nReceived: November 28, 2023. Revised: January 16, 2024. Editorial Decision: January 31, 2024. Accepted: February 2, 2024 \n# The Author(s) 2024. Published by Oxford University Press on behalf of the American Medical Informatics Association.   \nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which \npermits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. \nJournal of the American Medical Informatics Association, 2024, 1–12 \nhttps://doi.org/10.1093/jamia/ocae029 \nResearch and Applications","metadata":{"loc":{"lines":{"from":93,"to":107}}}}],["c747dcfd-46a1-4179-8f89-906899475052",{"pageContent":"Journal of the American Medical Informatics Association, 2024, 1–12 \nhttps://doi.org/10.1093/jamia/ocae029 \nResearch and Applications \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":105,"to":108}}}}],["aef9560c-64de-4f95-88b2-f55dd7bdbb71",{"pageContent":"Yet, the practical benefits of such LLM-generated defini-\ntions have not been studied extensively so far, something we \naim to address. In this article, we conclusively demonstrate \nthat  the  existence of  these artificial definitions for  a  large \nmajority of  biomedical concepts is  able to  substantially \nenhance the quality of textual representations obtained using \nthe “Learning of Ontological Representations through Defi-\nnitions and textual representations” strategy (LORD),\n11\nby \nincluding such definitions in  the  training data of  our  new \nmodel and assessing its impact on downstream tasks.\nOur second contribution, a self-distillation approach, takes \nadvantage of the existence of this broad set of definitions to \naccelerate the  convergence process of  the  LORD training \nstrategy, thereby achieving superior biomedical knowledge \nacquisition at a reduced loss of general language understand-\ning capabilities.\nCombining these 2 strategies, we train a new biomedical","metadata":{"loc":{"lines":{"from":1,"to":19}}}}],["bbe94736-fb70-4a31-98f6-0b8123217883",{"pageContent":"strategy, thereby achieving superior biomedical knowledge \nacquisition at a reduced loss of general language understand-\ning capabilities.\nCombining these 2 strategies, we train a new biomedical \nsemantic model, BioLORD-2023. We  evaluate our  newly \ntrained BioLORD-2023 model on a broad spectrum of down-\nstream tasks, including biomedical concept representation \n(BCR), semantic textual similarity (STS), and named entity \nlinking (NEL), with considerable gains across the entire range \nof tasks.\nOur third and last contribution is the release of our first \nmultilingual clinical language model, enabling the  retrieval \nand the concept normalization of content in up to 50 lan-\nguages, thanks to  the  cross-lingual distillation strategy \ndescribed by Reimers et al.\n19\nand a multilingual alignment \ndictionary built from SNOMED—CT\n17\nusing LaBSE.\n20\nWe evaluate this new multilingual model based on the test \nsuite developed for multilingual-SapBERT,\n21\na similar model","metadata":{"loc":{"lines":{"from":16,"to":40}}}}],["a87ce33a-c0f2-43c0-801f-4eea901333ae",{"pageContent":"dictionary built from SNOMED—CT\n17\nusing LaBSE.\n20\nWe evaluate this new multilingual model based on the test \nsuite developed for multilingual-SapBERT,\n21\na similar model \nwhich is widely considered as the current state of the art in \nthe domain. We also evaluate the quality of the distillation \nprocess using our evaluation metrics for  the  English \nlanguage.\nTo summarize, our 3 main contributions are as follows:\n1)  The expansion of our training corpus by supplementing \nits existing knowledge with new LLMs-generated defini-\ntions for 400 000 concepts, fusing knowledge graph and \nLLM insights inside the LORD pretraining. \n2)  The introduction of a novel self-distillation technique to \nspeed up  biomedical knowledge acquisition while pre-\nserving the  language understanding capabilities of  the \nBioLORD-type models. \n3)  The delivery of a state-of-the-art multilingual model for \nthe biomedical domain, using a proven cross-lingual dis-\ntillation technique. \nRelated works","metadata":{"loc":{"lines":{"from":33,"to":57}}}}],["4d7ae67e-93d0-4c4d-aea9-bb0478543416",{"pageContent":"BioLORD-type models. \n3)  The delivery of a state-of-the-art multilingual model for \nthe biomedical domain, using a proven cross-lingual dis-\ntillation technique. \nRelated works\nBefore delving into the details of our methodology, we pro-\nvide a short description of the context in which this work \nfinds its place, the technologies used in this article, and the \nprevious efforts which made this work possible, starting with \nBKGs.\nBiomedical knowledge graphs\nBKGs are  graph-based representations of  biomedical data \nand knowledge, where nodes represent entities (eg, genes, dis-\neases, drugs) and edges represent relationships (eg, interac-\ntions, associations, causations) between these entities. BKGs \ncan  be  classified by  their scope, curation strategy, and \nstructure, and  they can  contain various types of  informa-\ntion.\n22\nSeveral applications and  tasks in  biomedicine and \nhealthcare have been shown to  benefit from BKGs, both","metadata":{"loc":{"lines":{"from":53,"to":73}}}}],["7ad20a0c-c384-4133-9d4b-2006ebb90589",{"pageContent":"structure, and  they can  contain various types of  informa-\ntion.\n22\nSeveral applications and  tasks in  biomedicine and \nhealthcare have been shown to  benefit from BKGs, both \nbecause BKGs can be used as reliable sources of information, \nand because they provide traceable explanations for answers \nwhich can be derived from them.\nUnified Medical Language System (UMLS)\n16\nand Systemat-\nized Nomenclature of Medicine—Clinical Terms (SNOMED— \nCT)\n17\nare  2  examples of  BKGs that  are  used to  standardize \nhealth and  clinical information. They differ from each other \nboth in scope and structure. UMLS, as a conglomerate of bio-\nmedical vocabularies, aims for large coverage and encompasses \nover 3.7  million concepts from 200þsource vocabularies, \nincluding SNOMED-CT; however, it does not provide consis-\ntent views for all its concepts. Conversely, SNOMED-CT aims \nto provide a reliable gold standard for electronic health record","metadata":{"loc":{"lines":{"from":69,"to":90}}}}],["595298a5-e99c-4de0-90a6-145e6a0cf6ae",{"pageContent":"including SNOMED-CT; however, it does not provide consis-\ntent views for all its concepts. Conversely, SNOMED-CT aims \nto provide a reliable gold standard for electronic health record \n(EHR) standardization, thanks to its meticulous formal logic- \nbased structure and approximately 358 000 clinical concepts.\nIn this work, we maximally leverage the strengths of both \nUMLS and  SNOMED-CT by  using them in  the  learning \nphases for which they are best suited. For instance, in con-\ntinuity with previous iterations of BioLORD, we employ the \nUMLS concepts and relationships as part of the contrastive \npretraining, where the  increased scope and diversity of \ndescribed relationships is  an  advantage. However, we  also \nemploy definitions from the Automatic Glossary of Clinical \nTerminology (AGCT),\n18\nwhich leverages the more standar-\ndized and consistently annotated graph of SNOMED-CT to \nenhance the  homogeneity and  reliability of  the  produced \ndefinitions.","metadata":{"loc":{"lines":{"from":88,"to":106}}}}],["d9d38551-8864-4961-b6d2-f59f39fafaf6",{"pageContent":"Terminology (AGCT),\n18\nwhich leverages the more standar-\ndized and consistently annotated graph of SNOMED-CT to \nenhance the  homogeneity and  reliability of  the  produced \ndefinitions.\nLarge language models in healthcare\nLLMs encompass various types of machine learning models \nwhich have been trained on vast amounts of text to either \nachieve some understanding of existing content or generate \noriginal content based on  instructions. They have recently \ndemonstrated remarkable capabilities in  NLP tasks and \nbeyond.\nLLMs have been used in various clinical applications.\n23–25\nOne such application is  medical transcription and  clinical \ncoding using the  International Classification of  Diseases, \nwhere LLMs have been used to  improve the  accuracy and \nefficiency of  converting spoken medical observations into \nwritten or structured EHRs.\n26\nLLMs also show promise in various clinical data analysis \ntasks. For  instance, they can  analyze patient data such as \nmedical records,\n23","metadata":{"loc":{"lines":{"from":101,"to":125}}}}],["af9eb48e-2f92-4abf-96bf-9dfd6265d33f",{"pageContent":"written or structured EHRs.\n26\nLLMs also show promise in various clinical data analysis \ntasks. For  instance, they can  analyze patient data such as \nmedical records,\n23\nor interpret imaging studies and labora-\ntory results.\n27,28\nThese insights can support diagnosis by doc-\ntors and other healthcare professionals.\n28\nFinally, LLMs can \nalso be used to identify clinical trial opportunities for patients \nby analyzing patient data such as medical records.\n29\nExamples of  large biomedical language models include \nMed-PALM,\n24\nGalactica,\n30\nClinicalGPT,\n31\nBioMedLM,\n32\nBioGPT,\n33\nand others. Commercial language models such as \nChatGPT\n15\nand GPT-4\n34\nhave also shown great capabilities \nin  Biomedical AI,\n25\ndespite lacking dedicated finetuning \nprocedures.\nRetrieval-augmented generation\nWhile LLMs have demonstrated remarkable capabilities in \nNLP tasks, they are prone to hallucinations, which can result \nin  incorrect diagnoses and  treatments, leading to  adverse","metadata":{"loc":{"lines":{"from":120,"to":160}}}}],["fe1c9fe5-61d4-44c5-96bf-44a68a15f2a4",{"pageContent":"While LLMs have demonstrated remarkable capabilities in \nNLP tasks, they are prone to hallucinations, which can result \nin  incorrect diagnoses and  treatments, leading to  adverse \neffects on  patients. RAG is  a  method that  can  be  used to \n2                                                                                                          Journal of the American Medical Informatics Association, 2024, Vol. 00, No. 0 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":158,"to":163}}}}],["d25db771-c712-4b36-8cca-c3a0fe95d609",{"pageContent":"reduce hallucinations in LLMs, as well as increase trust in AI- \nbased tools by  explicitly linking their output to  external \nknowledge.\nRAG involves augmenting LLMs with information \nretrieval (IR) systems, which can  provide relevant content \nretrieved from external corpora as references. By incorporat-\ning  external knowledge, retrieval-augmented LLMs can \nanswer in-domain questions that cannot be  answered by \nsolely relying on the world knowledge stored in the model’s \nown parameters.\nIR systems often make use of pretrained models for dense \npassage retrieval (DPR) and baseline systems such as BM25, \na  traditional IR  strategy that uses term frequency-inverse \ndocument frequency weighting to rank documents based on \ntheir relevance to a query. In this work, we focus on creating \na dense concept and sentence representation model which is \nwell suited for  use,  among other tasks, as  a  DPR model \nwithin a biomedical RAG pipeline.\nBiomedical representation learning","metadata":{"loc":{"lines":{"from":1,"to":19}}}}],["085ddfa8-9562-4f42-8bf4-9b90f75ed456",{"pageContent":"a dense concept and sentence representation model which is \nwell suited for  use,  among other tasks, as  a  DPR model \nwithin a biomedical RAG pipeline.\nBiomedical representation learning\nTo build a system capable of retrieving content relating to a \nconcept by one of its names, the underlying models must be \nfamiliar with the vast biomedical terminology and the mean\n-\ning of the underlying concepts. Because of the daunting scale \nof clinical terminology, in-domain pretraining is insufficient \nto cover long multiword expressions accurately. Therefore, a \nnow large body of work attempts to produce better represen-\ntations using BKGs as a source, due to their extensive cover-\nage of biomedical concepts.\nAlthough multiple variations of  the  strategy exist, most \nstate-of-the-art models prior to 2022 focused on learning rep-\nresentations of biomedical entities based on the synonyms of \nentities, in a contrastive manner. Since then, BioLORD-2022","metadata":{"loc":{"lines":{"from":16,"to":33}}}}],["e96f02b8-92f0-46e1-9d76-830338321f99",{"pageContent":"state-of-the-art models prior to 2022 focused on learning rep-\nresentations of biomedical entities based on the synonyms of \nentities, in a contrastive manner. Since then, BioLORD-2022 \nwas introduced to  avoid spurious token-based overfitting \nusing more of the relationships found in the BKGs, and by \nusing full definitions to extract more fine-grained informa-\ntion out of medical knowledge bases. However, BioLORD- \n2022 did not make use of LLMs to expand the training data, \nand it only used concept definitions during the pretraining \nphase. BioLORD-2022 models also suffer from a consider-\nable performance decrease in general language understanding \ncompared to  the  original pretrained language models they \nwere based on, which is undesirable. In this work, we extend \nthe BioLORD-2022 training strategy to fix these deficiencies.\nCross-lingual distillation of knowledge\nIn addition to this, we provide a multilingual variant of our \nnew model. While some multilingual biomedical models","metadata":{"loc":{"lines":{"from":31,"to":47}}}}],["2e380b54-1d25-4ebf-b601-1bcfe1377989",{"pageContent":"Cross-lingual distillation of knowledge\nIn addition to this, we provide a multilingual variant of our \nnew model. While some multilingual biomedical models \nalready exist, such as Multilingual SapBERT, their perform-\nance has been lower than the monolingual English models. \nThis is because they rely on the existence of sufficient non- \nEnglish training data during pretraining, but the existence of \nsuch data for the biomedical domain is scarce, and results in \nsubpar generalization.\nOne of the goals of this work is to improve upon this state \nof the art using proven techniques for cross-lingual distilla-\ntion.\n19\nCross-lingual distillation trains a multilingual model \nto produce the same output as a target English model irre-\nspective of the language in which a concept name is provided, \nsuch that “Fever,” “Fiebre,” and “Fieber” produce the same \noutput.\nMethods\nIn this work, we train a concept and sentence representation \nmodel fine-tuned for biomedical content, following a novel","metadata":{"loc":{"lines":{"from":45,"to":65}}}}],["80130cee-0987-48ef-8981-5b60d1d0223a",{"pageContent":"such that “Fever,” “Fiebre,” and “Fieber” produce the same \noutput.\nMethods\nIn this work, we train a concept and sentence representation \nmodel fine-tuned for biomedical content, following a novel \n3-step strategy (see Figure 1),  and evaluate its potential on \nseveral downstream tasks, all described in the following sub-\nsections. We also provide justifications for the changes made \nto  the  previous iterations of  this  strategy, with the  use  of \nablation studies.\nTraining data\nIn addition to the algorithmic changes described in the next \nsection, a core aspect of our work hinges on the new data we \nleverage during the training, which we describe further in this \nsection.\nIn addition to the training data already used in previous \nworks, this study makes use of a LLM to generate a large set \nof  definitions of  biomedical concepts (grounded using the \ninformation contained in the SNOMED-CT ontology as con-\ntext, as well as the information stored in the weights of the","metadata":{"loc":{"lines":{"from":61,"to":80}}}}],["4112e071-953e-4248-be0b-f550733e3c44",{"pageContent":"of  definitions of  biomedical concepts (grounded using the \ninformation contained in the SNOMED-CT ontology as con-\ntext, as well as the information stored in the weights of the \nLLM itself). We leave the precise description of the procedure \nand its expert evaluation to the paper introducing the dataset \n[18] but we provide the most relevant details in the following \nparagraph.\nIn  this  new study, the  preexisting UMLS definitions are \nindeed complemented by  400 000 biomedical definitions \nfrom the AGCT, a large-scale biomedical dictionary of clini-\ncal  concepts which we  generated using the  SNOMED-CT \nontology and the GPT-3.5 language model. A subset of the \ngenerated definitions was evaluated by NLP researchers with \nbiomedical expertise on 3 metrics: factuality, insight, and flu-\nency; based on these metrics and a strict 6-grade quality rat-\ning, it was determined that more than 80% of the generated \ndefinitions would be usable for patient education, while more","metadata":{"loc":{"lines":{"from":78,"to":94}}}}],["d6486547-d836-46db-9a50-55062257ba59",{"pageContent":"ency; based on these metrics and a strict 6-grade quality rat-\ning, it was determined that more than 80% of the generated \ndefinitions would be usable for patient education, while more \nthan 96% appeared useful for machine learning tasks. In this \nwork, we set out to confirm whether that is truly the case in a \npractical scenario.\nBioLORD-2023 also makes use of a newer version of the \nUMLS ontology (v2023AA) to generate its textual descrip\n-\ntion, compared to  BioLORD-2022 (which used v2020AB). \nThis enables the new version of the model to become more \naware of  recent developments in  the  field, for  example, \nincluding knowledge related to the COVID-19 pandemic.\nTraining strategy\nContrastive phase\nTo obtain our BioLORD-2023 model, we first make use of \nthe  contrastive objective devised by  van  den  Oord et  al,\n35\nwith the goal of instilling biomedical knowledge into a base \nlanguage model. More precisely, we make use of the LORD \nstrategy\n11","metadata":{"loc":{"lines":{"from":92,"to":113}}}}],["b5d0da3d-a001-4fae-a812-54b9c1cea21d",{"pageContent":"the  contrastive objective devised by  van  den  Oord et  al,\n35\nwith the goal of instilling biomedical knowledge into a base \nlanguage model. More precisely, we make use of the LORD \nstrategy\n11\nin which batches of concept names and their defini-\ntions are fed to the language model, and where the distance \nbetween the representation of a concept name and the repre-\nsentation of its definition should be minimized while maxi-\nmizing the distance between a concept and the definition of \nthe other concepts in the batch.\nFor instance, the representations by the language model of \n“ranitidine” and of “an H2-antagonist substance frequently \nused to treat peptic ulcer”\n16\nare encouraged to be as close as \npossible, while remaining far  from the  representations of \n“aspirin” and of “a synthetic compound used medicinally to \nrelieve mild or  chronic pain and to  reduce fever and","metadata":{"loc":{"lines":{"from":108,"to":127}}}}],["8330d336-1642-46e8-97f6-ec1b9c9075c1",{"pageContent":"possible, while remaining far  from the  representations of \n“aspirin” and of “a synthetic compound used medicinally to \nrelieve mild or  chronic pain and to  reduce fever and \nJournal of the American Medical Informatics Association, 2024, Vol. 00, No. 0                                                                                                           3 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":125,"to":129}}}}],["ec822c0e-cc31-4c0f-9e27-aee40dafb602",{"pageContent":"inflammation”,\n16\nwhich are related to another concept of the \nbatch (as illustrated in Figure 2).\nIn this work, we make use of the improved initialization \nstrategy developed by Remy et al,\n36\nwhich involves adapting \nthe STAMB2 model\n37\nused for the initialization of \nBioLORD-2022 to  the  STS  tasks of  our  benchmark in  a \nmulti-task setup, prior to  applying our  contrastive phase. \nMulti-task setups have been shown to be effective in scenar-\nios  where catastrophic forgetting is  possible as  a  result of \ncontinual learning.\n38\nBy aligning the STAMB2 model to the \nhuman preference of STS datasets prior to applying the con-\ntrastive learning phase of BioLORD, BioLORD-2023 produ-\nces  representations of  medical concepts which align more \nclosely with human judgment.\nWe also insert this adaptation phase a second time, after \nthe  contrastive learning stage of  BioLORD. This further \nenhances the  BioLORD-2023 model’s performance on STS \ntasks.\nSelf-distillation phase","metadata":{"loc":{"lines":{"from":1,"to":27}}}}],["6b39ba05-542d-4c74-9233-665641d66e54",{"pageContent":"the  contrastive learning stage of  BioLORD. This further \nenhances the  BioLORD-2023 model’s performance on STS \ntasks.\nSelf-distillation phase\nThe contrastive pretraining strategy described earlier was \nshown to  yield excellent results in  biomedical knowledge \nacquisition. We briefly summarize next the findings of BioL-\nORD-2022\n11\nand refer to the paper for details.\nCompared to their STAMB2 base,\n37\nmodels trained using \nthe  BioLORD-2022 methodology show a  visible improve-\nment in clinical sentence understanding and greatly improved \nBCR capabilities.\nUnlike models trained using the SapBERT training strat-\negy, BioLORD-2022 models remained proficient in the han-\ndling of  sentence-level semantics. We  attribute this  to  our \nchoice of  model initialization and  the  inclusion of  concept \ndefinitions in  the  BioLORD-2022 training strategy, which \nsucceeded in preventing a catastrophic forgetting of sentence \nparsing during the biomedical knowledge acquisition phase.","metadata":{"loc":{"lines":{"from":24,"to":46}}}}],["3586cce0-7071-41d9-9471-bf2eb76a6912",{"pageContent":"definitions in  the  BioLORD-2022 training strategy, which \nsucceeded in preventing a catastrophic forgetting of sentence \nparsing during the biomedical knowledge acquisition phase.\nHowever, the addition of the definitions did not prove suf-\nficient to avoid a measurable degradation of the performance \nof  the  model in  general-purpose semantic similarity tasks. \nThis degradation cannot be  solely attributed to  a  loss  of \nknowledge about general-domain concepts, as the perform-\nance degradation remained visible even when no  general- \ndomain knowledge was  required for  solving the  semantic \ntask.\nWe attribute a large part of this performance degradation \nto  the  semantic space distortion induced by  the  extensive \nFigure 1. Compared to BioLORD-2022 (left), BioLORD-2023 involves a more advanced training strategy, composed of 3 phrases: a contrastive phase","metadata":{"loc":{"lines":{"from":44,"to":57}}}}],["2799f9b9-da49-40ae-9bd4-2c4b82f8b25a",{"pageContent":"Figure 1. Compared to BioLORD-2022 (left), BioLORD-2023 involves a more advanced training strategy, composed of 3 phrases: a contrastive phase \n(further illustrated in Figure 2),  a self-distillation phase (illustrated in Figure 3),  and a weight-averaging phase (all further described in the following \nsubsections).\n4                                                                                                          Journal of the American Medical Informatics Association, 2024, Vol. 00, No. 0 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":57,"to":61}}}}],["56e8e511-e6b4-4240-87aa-d16e8455cffb",{"pageContent":"contrastive learning of concept names and their definitions, \nwhich only elicits a select few aspects of the STS task, blow-\ning up the  importance of these aspects considerably at the \nexpense of other aspects of language understanding, thereby \nresulting in a loss of calibration of the model.\nTo counter-balance this, we propose to substitute the unsu-\npervised contrastive learning phase by a supervised objective, \ntaking into  account the  learnings of  the  contrastive phase \nwithout having to resort to a contrastive objective. To this \nend, we generate concept embeddings for the 4 million bio-\nmedical concepts contained in UMLS (using the BioLORD- \n2023-C model), and finetune a base model (which has not \nundergone the contrastive learning phase) to accurately pre-\ndict these distilled concept embeddings via a learned projec-\ntion followed by  a  standard mean-squared-error loss  (see  \nFigure 3).\nWe call this process the “self-distillation phase,” as we dis-","metadata":{"loc":{"lines":{"from":1,"to":17}}}}],["b84e64d6-bf25-4288-bf0c-81046136aa50",{"pageContent":"dict these distilled concept embeddings via a learned projec-\ntion followed by  a  standard mean-squared-error loss  (see  \nFigure 3).\nWe call this process the “self-distillation phase,” as we dis-\ntill the knowledge acquired by the contrastive model into a \npast version of itself in a supervised manner, hoping that this \nwill better preserve its existing knowledge.\nLike in  the  previous phase, we  leverage the  knowledge \nextracted from the  knowledge graphs and the  LLM by \nFigure 2. BioLORD aims to bring the representation of biomedical concept names (ʘ) and their definitions (�)   closer to each other, to ground the name \nrepresentations with knowledge from the definitions. This is illustrated for the Ranitidine and Aspirin concepts from UMLS. Knowledge from the \nontology’s relational knowledge graph is injected by extending the set of known definitions with automatically generated definitions (�)   from the","metadata":{"loc":{"lines":{"from":14,"to":25}}}}],["6aac7851-5cf5-4b6f-a3ef-de4292a9921b",{"pageContent":"ontology’s relational knowledge graph is injected by extending the set of known definitions with automatically generated definitions (�)   from the \nAutomatic Glossary of Clinical Terminology, as well as with simpler template-based descriptions sampled from UMLS relationships (⌘�). Contrastive \nlearning is applied to attract the representations of compatible pairs (\nʘ, �,  or �)  and repel incompatible ones.\nFigure 3. In the self-distillation phase, the knowledge acquired during the contrastive phase is imbued into the base model, using a more direct training \nstrategy. The representation of each textual variant of a concept is trained to map the average of the contrastive model representation of its name and \ndefinition.\nJournal of the American Medical Informatics Association, 2024, Vol. 00, No. 0                                                                                                           5","metadata":{"loc":{"lines":{"from":25,"to":32}}}}],["5c2bf022-d571-4093-a1a3-5affece562a2",{"pageContent":"definition.\nJournal of the American Medical Informatics Association, 2024, Vol. 00, No. 0                                                                                                           5 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":31,"to":33}}}}],["39ef623a-12e2-47db-a31a-82c99342da69",{"pageContent":"incorporating the concept definitions in the distillation proc-\ness. We do this by first producing embeddings for concept \nnames and their generated concept definitions using the \nmodel resulting from the  contrastive phase of  BioLORD- \n2023, and by subsequently averaging these 2 representations \nfor each concept and using the result as the regression target \nduring self-distillation, for  both the  concept name and  its \ndefinition.\nTo improve the training speed, we reduce the latent space \nof produced embeddings to 64 dimensions through principal \ncomponent analysis (PCA). Finally, we train a randomly ini-\ntialized linear projection head on top of the base STAMB2- \nSTS  model to  predict these 64-dimension embeddings (see  \nFigure 3).\nThis supervised self-distillation phase possesses several key \nadvantages: firstly, by including the concept definitions in the \nprocess to produce the concept embeddings, better represen-\ntations can be learnt for biomedical concepts whose name is","metadata":{"loc":{"lines":{"from":1,"to":18}}}}],["05d70513-4f23-4a24-a8b7-fb78ed3a88f0",{"pageContent":"advantages: firstly, by including the concept definitions in the \nprocess to produce the concept embeddings, better represen-\ntations can be learnt for biomedical concepts whose name is \notherwise uninformative or difficult for the model to memo-\nrize; secondly, it is considerably faster than the contrastive \nlearning phase, which is likely to cause less forgetting of the \noriginal task for an identical level of new knowledge acquisi-\ntion\n39\n; thirdly, it further enables the language model to lever-\nage  its  existing features to  obtain the  desired knowledge, \nwithout having to distort them to reduce the in-domain ani-\nsotropy,\n40–42\nand fourthly, it should be possible to apply this \ndistillation phase on a different base model than the one used \nduring the  contrastive learning phase, taking advantage of \nimproved base models at a limited training cost (we, how-\never, leave the exploration of this aspect for future works).\nWeight-averaging phase","metadata":{"loc":{"lines":{"from":16,"to":35}}}}],["6cdd3b9a-acbf-4013-861e-83eb50255900",{"pageContent":"improved base models at a limited training cost (we, how-\never, leave the exploration of this aspect for future works).\nWeight-averaging phase\nAn interesting aspect of the self-distillation phase described \nabove is that it hinges on a randomly initialized projection \nhead added on top of the base sentence representation model. \nAs a result of this, different random seeds result in slightly \ndifferent models, focusing on different aspects of the sentence \nembedding.\nWhile a commonly used technique in this scenario, called \nhyperparameter tuning, aims to select the best model from \nmultiple experiments based on  a  held-out validation set, \nWortsman et  al\n43\ndiscovered a  better strategy, which they \nnamed “model soups,” and which consists in the averaging \nof the weight of the parameters of several fine-tuned models.\nIndeed, Wortsman et al. were able to show that it is often \npossible to improve the accuracy and robustness of the result-","metadata":{"loc":{"lines":{"from":33,"to":51}}}}],["e9a8d513-becb-4df6-9f77-0555b361f987",{"pageContent":"of the weight of the parameters of several fine-tuned models.\nIndeed, Wortsman et al. were able to show that it is often \npossible to improve the accuracy and robustness of the result-\ning system by averaging the weights of multiple models, each \nfine-tuned with different hyperparameter configurations. \nUnlike a  traditional ensemble, no  additional inference or \nmemory costs are incurred as a result of the merge, irrespec-\ntive of the number of models being merged, which makes this \ntechnique particularly attractive for  DPR models, where a \nfast inference is highly desirable. We evaluate the impact of \nthe weight averaging in Discussion section.\nCross-lingual distillation\nFinally, we further make use in this work of the technique \ndescribed by Reimers et al,\n19\nwhich consists of using a paral-\nlel corpus to distill a high-quality monolingual model into a \nmultilingual model yielding similar representations for a text \nin that language and translations sourced from the corpus.","metadata":{"loc":{"lines":{"from":49,"to":67}}}}],["a1cf794b-47b3-4e36-b0a5-ec9ed8881f87",{"pageContent":"lel corpus to distill a high-quality monolingual model into a \nmultilingual model yielding similar representations for a text \nin that language and translations sourced from the corpus.\nWe cross-lingually distill the representations of our English \nmodel into the  “paraphrase-multilingual-mpnet-base-v2” \nlanguage model introduced in the same paper as the distilla\n-\ntion technique, and which supports 50þlanguages.\nIn particular, we make use of an aligned corpus generated \nfrom the regional releases of SNOMED-CT, using the Google \nLaBSE bi-text mining model,\n20\nand  which we  describe in \nmore detail in our EmP 2022 publication.\n44\nThis aligned cor-\npus contains alignments for the following languages: English, \nSpanish, French, German, Dutch, Danish, and Swedish.\nWhile we did not investigate this in the current version of \nBioLORD-2023-M, this  corpus could be  complemented by \nmultilingual annotations from UMLS (and in particular its","metadata":{"loc":{"lines":{"from":65,"to":85}}}}],["c5f168f4-b787-4f62-95fc-05c99e3e280c",{"pageContent":"While we did not investigate this in the current version of \nBioLORD-2023-M, this  corpus could be  complemented by \nmultilingual annotations from UMLS (and in particular its \nMESH subset), to increase language coverage. We leave this \ninvestigation to a follow-up work.\nEvaluation methodology\nAs  mentioned in  the  abstract, an  extensive test  suite is \nrequired to evaluate the capabilities of semantic models. The \nfollowing paragraphs list  and  describe the  various bench-\nmarks used to evaluate BioLORD-2023, covering STS, con-\ncept representations, and entity linking, all in the biomedical \nand clinical domains.\nClinical semantic textual similarity\nSTS is an NLP task measuring the degree of semantic align-\nment between NLP models and human judgment, by assign-\ning similarity scores to a pair of 2 sentences, usually from 0 \nto 5, and computing the correlation between scores obtained \nby expert human judgment and model-assigned scores.","metadata":{"loc":{"lines":{"from":83,"to":100}}}}],["c119dc5d-df4c-4085-8b8d-2ed3db2ce84e",{"pageContent":"ing similarity scores to a pair of 2 sentences, usually from 0 \nto 5, and computing the correlation between scores obtained \nby expert human judgment and model-assigned scores.\nWe evaluate the STS capabilities of the models on 5 popu-\nlar  benchmarks: 3  biomedical or  clinical ones (MedSTS,\n45\nMedNLI-S,\n46\nBIOSSES\n47\n)  and  2  general purposes bench-\nmarks (SICK\n48\nand STS-Benchmark\n49\n) For readers unfamiliar \nwith these datasets, we provide a brief introduction for each \nof them in Appendix SC.\nBiomedical concept representation\nKnown as BCR, this task concerns the mapping of biomedical \nconcepts to a vector latent space, whose features enable clas-\nsifying these concepts or  deriving properties from them. It \ncan be relevant for numerous biomedical tasks including dis-\nease subtype annotations.\n50\nFollowing the approach of Kalyan and Sangeetha,\n51\nwe eval-\nuate our model using 4 benchmarks: EHR-RelB,\n52\nUMNSRS- \nSimilarity,\n53\nUMNSRS-Relatedness,\n53\nand MayoSRS.\n54\nFor","metadata":{"loc":{"lines":{"from":98,"to":135}}}}],["7824f17d-3cae-42d0-a2e4-6de743016d58",{"pageContent":"50\nFollowing the approach of Kalyan and Sangeetha,\n51\nwe eval-\nuate our model using 4 benchmarks: EHR-RelB,\n52\nUMNSRS- \nSimilarity,\n53\nUMNSRS-Relatedness,\n53\nand MayoSRS.\n54\nFor \nreaders unfamiliar with these datasets, we provide a brief intro-\nduction for each of them in Appendix SC.\nBiomedical named entity linking\nThe  task of  biomedical concept name normalization, also \nreferred to  as  NEL in  the  broader literature, concerns the \nmapping of  free-form text  describing clinical disorders or \nconcepts to a fixed list of biomedical concepts, such as the \nelements of the biomedical ontology.\nTo showcase improvements in NEL, we reuse the evalua-\ntion setup devised by Portelli et al,\n55\nwhere biomedical lan-\nguage models were evaluated on a set of 5 datasets of varying \nlevels of formality, listed here in the reverse order of formality \n(least formal first): TwiMed-Twitter,\n56\nSMM4H,\n57\nPsyTar,\n58\nCADEC,\n59\nand TwiMed-PubMed.\n56\nFor readers unfamiliar","metadata":{"loc":{"lines":{"from":122,"to":160}}}}],["5e59f880-030e-44a2-b1ee-885d432dbafd",{"pageContent":"levels of formality, listed here in the reverse order of formality \n(least formal first): TwiMed-Twitter,\n56\nSMM4H,\n57\nPsyTar,\n58\nCADEC,\n59\nand TwiMed-PubMed.\n56\nFor readers unfamiliar \nwith these datasets, we provide a brief introduction for each \nof them in Appendix SC.\n6                                                                                                          Journal of the American Medical Informatics Association, 2024, Vol. 00, No. 0 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":149,"to":164}}}}],["b600bec5-81eb-4e79-9655-ffc3c4b6f203",{"pageContent":"Hyperparameters and training details\nIn  order to  focus on  the  effect of  the  inclusion of  LLM- \ngenerated definitions in the training set, and on our improved \ntraining strategy including the novel self-distillation step, all \nthe experiments that follow are finetuned from the same base \nmodel as BioLORD-2022.\nThis base model had a size identical to the other baseline \nmodels evaluated in this study, enabling a fair comparison \nbetween them. We  also report some interesting findings \nabout larger models in Appendix SA.\nTo facilitate the replication of our results, we release the \ncode used in the various phases of our training jointly with \nthis article, and we detail our choices of hyperparameters in \nAppendix SB.\nResults\nThis section presents the  empirical evaluation results of \nBioLORD-2023, in comparison to existing models. In order \nto gain insights into the modified training strategy, compared \nto BioLORD-2022, a number of ablation results are provided","metadata":{"loc":{"lines":{"from":1,"to":19}}}}],["b62c0bdf-8e57-4011-8fa8-8c1475d0eaa8",{"pageContent":"BioLORD-2023, in comparison to existing models. In order \nto gain insights into the modified training strategy, compared \nto BioLORD-2022, a number of ablation results are provided \nas well. Finally, our multilingual model is also evaluated.\nFor our evaluation of the English BioLORD-2023, we fol-\nlow  a  structure similar to  BioLORD-2022, and  analyze in \nturn the suitability of the model for several tasks including \nclinical-STS, BCR, and NEL (as described in the previous sec\n-\ntion). To produce fair results, all models undergo our multi-\ntask finetuning, which was shown to improve results across \nthe board.\nWe report these results in Table 1.  Results for additional \nbaseline models\n23,60\nare reported in Appendix SD.\nWe also conduct an ablation study, showing the effect of \nthe various training phases of the BioLORD-2023 methodol-\nogy. To  compare the  effect of  the  training strategies more \neffectively, we  report the  absolute improvements over the","metadata":{"loc":{"lines":{"from":17,"to":36}}}}],["b88fbc84-ba91-4c49-85a1-8057ab279388",{"pageContent":"the various training phases of the BioLORD-2023 methodol-\nogy. To  compare the  effect of  the  training strategies more \neffectively, we  report the  absolute improvements over the \nbase model (STAMB2 in all cases, for BioLORD-2022 and \n2023 models).\nResults are shown in Table 2.\nIn addition, we separately evaluate our cross-lingual model \nusing both the English test suite (to evaluate the distillation \nquality) and a multilingual NEL task, XL-BEL.\nFor XL-BEL, we report the 3 European languages on which \nboth multilingual SapBERT and BioLORD-2023-M were \nfinetuned: German, Spanish, and English.\nWe report those results in Table 3.\nTo support the research community, we release on Hug-\ngingFace the models we trained, at all 3 stages of our pipe-\nline. This will also enable other researchers to pick the model \nthat is best suited for their experiments.\nhttps://huggingface.co/FremyCompany/BioLORD-2023\nDiscussion\nThis section provides insights into the  results, structured","metadata":{"loc":{"lines":{"from":34,"to":53}}}}],["96adeb46-5561-4e46-a3e8-fa5e9775f451",{"pageContent":"that is best suited for their experiments.\nhttps://huggingface.co/FremyCompany/BioLORD-2023\nDiscussion\nThis section provides insights into the  results, structured \naccording to the benchmark tasks, covering the absolute met-\nrics reported in Table 1 and the impact of training strategies \nas  reported in  Table 2.  After discussing the  results for  the \nEnglish BioLORD-2023, we will demonstrate the quality of \nits  multi-lingual counterpart, BioLORD-2023-M, by  refer-\nring to Table 3.\nClinical semantic textual similarity\nAs can be seen in Table 1,  our new model BioLORD-2023 \ndemonstrates a considerably increased performance on bio-\nmedical tasks such as MedSTS (from 86.3 to 88.3), BIOSSES \n(from 84.0 to 86.1), and MedNLI-S (from 89.9 to 92.4) while \nalso increasing its performance in general-purpose tasks like \nthe STS-Benchmark (from 86.5 to 87.8) and SICK (from 89.3 \nto 90.3).\nOur BioLORD training strategy therefore achieved signifi-","metadata":{"loc":{"lines":{"from":50,"to":68}}}}],["274100f2-da34-40c5-a36f-784d6125b7f0",{"pageContent":"also increasing its performance in general-purpose tasks like \nthe STS-Benchmark (from 86.5 to 87.8) and SICK (from 89.3 \nto 90.3).\nOur BioLORD training strategy therefore achieved signifi-\ncant gains in  the  biomedical domain, while maintaining a \nhigh performance in the general-purpose domain. Compared \nto the original STAMB2 model, our model only suffered a \nnegligible drop of  0.2  and  0.4  points in  STS-B and  SICK, \nrespectively. These tasks are not relevant to our main objec-\ntive of enhancing the biomedical knowledge of the model, so \nwe  did  not  optimize our  training for  them. Therefore, we \nregard such a minor performance degradation as a success, as \nit reflects the (now excellent) trade-off between generalization \nand specialization that is inherent to any finetuning process.\nThe  performance of  biomedical semantic models on  the \ngeneral domain was shown in previous studies\n36\nto be a good \nindicator of the NEL performance of the models in less for-","metadata":{"loc":{"lines":{"from":65,"to":83}}}}],["87f992f1-a8d4-4905-8be6-951c6db9dd69",{"pageContent":"The  performance of  biomedical semantic models on  the \ngeneral domain was shown in previous studies\n36\nto be a good \nindicator of the NEL performance of the models in less for-\nmal contexts, such as healthcare information posted on social \nmedia, a crucial information source for pharmacovigilance. \nWe also believe that it is a good indication of model robust-\nness, as not all clinical notes are written in formal and unam-\nbiguous medical language.\nThe above results demonstrate with confidence that \nBioLORD-2023 is  the  new state-of-the-art semantic model \nfor the biomedical domain.\nBiomedical concept representation\nIn  this  section, we  analyze the  performance of  the  embed-\ndings produced by  state-of-the-art models for  the  task of \nmodeling biomedical concepts.\nBioLORD-2023 obtains superior performance on  all  the \nconsidered BCR benchmarks, as reported in Table 1.  It per-\nforms particularly well on  the  EHR-Rel-B benchmark (the","metadata":{"loc":{"lines":{"from":79,"to":98}}}}],["3d7e6df8-e31a-4e8a-bddd-85d54268150f",{"pageContent":"BioLORD-2023 obtains superior performance on  all  the \nconsidered BCR benchmarks, as reported in Table 1.  It per-\nforms particularly well on  the  EHR-Rel-B benchmark (the \nmost exhaustive and  recent one) as  well as  the  UMNSRS- \nSimilarity benchmark.\nThe ablation results of Table 2 show that the evolution of \nthe scores over the training phase follows a similar pattern to \nthe clinical STS tasks already presented in the previous sub-\nsection, although there appears to be some trade-off between \nSimilarity tasks and Relatedness tasks.\nThis time again, the results are consistent with our hypoth-\nesis  that BioLORD-2023 is  the  current best biomedical \nembedder, even beating more complex systems that explicitly \ncombine graphs and text embedders such as Kalyan and San-\ngeetha\n51\nand Mao and Fung.\n61\nWe refer to these papers for \nmore details on their results and methodology.\nBiomedical named entity linking\nOverall, the strong results for the biomedical NEL tasks con-","metadata":{"loc":{"lines":{"from":96,"to":117}}}}],["f612d507-e20c-4356-8d56-1740e96a7913",{"pageContent":"51\nand Mao and Fung.\n61\nWe refer to these papers for \nmore details on their results and methodology.\nBiomedical named entity linking\nOverall, the strong results for the biomedical NEL tasks con-\nfirm that BioLORD-2023 performs well both on more formal \ndatasets such as TwiMed-PM and on informal medical data-\nsets, such as TwiMed-TW.\nUnlike the STS and BCR tasks, we do not notice a similarly \nclear pattern of  decreased performance for  the  ablation \nstudies. We suspect that NEL is  a task that favors heavily \ncontrastive learning strategies, making the  gains of  the \nself-distillation less relevant.\nJournal of the American Medical Informatics Association, 2024, Vol. 00, No. 0                                                                                                           7 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":111,"to":127}}}}],["c609e2fc-d336-4d00-bff2-aa925dfa2b86",{"pageContent":"Cross-lingual distillation\nIn this section, we evaluate the performance of the multilin-\ngual BioLORD model (referred to as BioLORD-2023-M) and \nfurther discuss its potential.\nWe evaluate BioLORD-2023-M in 2 ways. Firstly, we eval-\nuate its performance on the same datasets used for our Eng-\nlish evaluation, to determine the impact of the multilingual \ndistillation on the model performance. Secondly, we assess its \nconcept name normalization capabilities for languages other \nthan English, such as Spanish and German, using the proce\n-\ndure used by Multilingual SapBERT.\nIn Table 3,  we report the performance of multilingual var-\niants of  SapBERT and  BioLORD on  the  English tasks on \nwhich their monolingual equivalents were evaluated before.\nAs a result of the distillation procedure, which focuses on \nbiomedical concept names, BioLORD-2023-M achieves \ncomparable or  superior performance on  BCR benchmarks \ncompared to  BioLORD-2023. When it  comes to  sentence-","metadata":{"loc":{"lines":{"from":1,"to":19}}}}],["3cff12bf-559e-4de1-953b-ab366fa76a1a",{"pageContent":"biomedical concept names, BioLORD-2023-M achieves \ncomparable or  superior performance on  BCR benchmarks \ncompared to  BioLORD-2023. When it  comes to  sentence- \nlevel STS tasks, some performance degradation is incurred, \nbut BioLORD-2023-M remains well ahead of its SapBERT \ncompetitors. These results indicate that the multilingual dis\n-\ntillation procedure was highly effective and displays strong \nperformance on English tasks for which the original model \nexcelled.\nWhen we consider the performance of these multilingual \nmodels on NEL tasks in English. This time again, we find \ncomparable performances between the original and the dis-\ntilled model, albeit the monolingual model usually performs \nslightly better. In all cases, BioLORD-2023-M performs con-\nsiderably better than multilingual SapBERT on these tasks.\nFinally, we also report in Table 3 the performance of multi-\nlingual SapBERT and multilingual BioLORD on the clinical","metadata":{"loc":{"lines":{"from":17,"to":34}}}}],["e38fc93e-503b-4631-b053-f0aef57901d5",{"pageContent":"siderably better than multilingual SapBERT on these tasks.\nFinally, we also report in Table 3 the performance of multi-\nlingual SapBERT and multilingual BioLORD on the clinical \nsubset of  XL-BEL, a  dataset specifically developed for  the \nTable 1. Performance characteristics of state-of-the-art biomedical models on STS (Pearson correlation), BCR (Spearman correlation), and NEL (Top1 \nAccuracy).\nBioSyn\n9\nSapBERT\n10\nBioLORD-2022BioLORD-2023\nSTSMedSTS\n45\n84.086.086.388.3\nMedNLI-S\n46\n89.590.589.992.4\nBIOSSES\n47\n92.189.384.086.1\nSICK\n48\n86.780.389.390.3\nSTS\n49\n79.481.986.587.8\n(average)86.385.687.289.0\nBCREHR-Rel-B\n52\n42.551.757.563.6\nUMNSRS-S\n53\n43.653.056.059.2\nUMNSRS-R\n53\n39.147.554.454.4\nMayoSRS-S\n54\n45.162.574.774.4\n(average)42.653.760.762.9\nNELTwiMed-TW\n56\n42.848.348.549.8\nSMM4H\n57\n33.143.446.547.7\nPsyTAR\n58\n52.464.864.766.3\nCADEC\n59\n35.340.458.763.0\nTwiMed-PM\n56\n65.370.170.469.4\n(average)45.853.457.859.2","metadata":{"loc":{"lines":{"from":32,"to":87}}}}],["010cd487-680f-49e6-808e-0ec2c16d13b0",{"pageContent":"(average)42.653.760.762.9\nNELTwiMed-TW\n56\n42.848.348.549.8\nSMM4H\n57\n33.143.446.547.7\nPsyTAR\n58\n52.464.864.766.3\nCADEC\n59\n35.340.458.763.0\nTwiMed-PM\n56\n65.370.170.469.4\n(average)45.853.457.859.2\nThe following models are evaluated: BioSyn (state-of-the-art in 2020), SapBERT (state-of-the-art in 2021), BioLORD-2022 (our baseline), and BioLORD- \n2023 (our new model). Bolding and a color code indicate the best and second-best results for a given task.\nTable 2. Performance characteristics of the BioLORD models obtained after each proposed training phase, relative to the STAMB2 performance (in \npercentage points), on STS (Pearson correlation), BCR (Spearman correlation), and NEL (Top1 Accuracy).\nSTAMB2\n37\n(base)BioLORD-2022BioLORD-2023-CBioLORD-2023-SBioLORD-2023\nSTSMedSTS\n45\n85.9þ0.4þ0.4þ1.612.4\nMedNLI-S\n46\n89.4þ0.5þ2.5þ2.713.0\nBIOSSES\n47\n90.7–6.7–4.5–5.3–4.6\nSICK\n48\n90.7–1.4–1.0–0.8–0.4\nSTS\n49\n88.0–1.5–1.1–1.0–0.2\n(average)89.0þ0.5þ1.5þ2.212.7\nBCREHR-Rel-B\n52\n47.1þ10.4þ11.2þ15.7116.5","metadata":{"loc":{"lines":{"from":71,"to":113}}}}],["57a5d49f-7c1e-46dc-8697-51e9f1721bff",{"pageContent":"MedNLI-S\n46\n89.4þ0.5þ2.5þ2.713.0\nBIOSSES\n47\n90.7–6.7–4.5–5.3–4.6\nSICK\n48\n90.7–1.4–1.0–0.8–0.4\nSTS\n49\n88.0–1.5–1.1–1.0–0.2\n(average)89.0þ0.5þ1.5þ2.212.7\nBCREHR-Rel-B\n52\n47.1þ10.4þ11.2þ15.7116.5\nUMNSRS-S\n53\n43.9þ12.1þ13.7115.3115.3\nUMNSRS-R\n53\n46.7þ07.7þ08.0109.1þ07.7\nMayoSRS-S\n54\n54.1120.6þ18.6þ15.9þ20.3\n(average)48.0þ12.7þ12.9þ14.0115.0\nNELTwiMed-TW\n56\n44.1þ04.4105.7þ03.7105.7\nSMM4H\n57\n38.4þ08.1þ08.5þ03.2109.3\nPsyTAR\n58\n56.5þ08.2þ08.9þ05.2109.8\nCADEC\n59\n36.9þ21.8126.2þ24.4þ26.1\nTwiMed-PM\n56\n62.8107.6þ04.9þ05.7þ06.6\n(average)47.7þ10.0þ10.8þ08.4111.5\nThe following models are evaluated: STAMB2 (our shared base model), BioLORD-2022 (our baseline), BioLORD-2023 (our new model), and an ablation \nstudy for each intermediary training phase (BioLORD-2023-C for the contrastive phase, and BioLORD-2023-S for the Self-Distillation phase; see Figure 1). \nBolding and a color code indicate the best and second-best results for a given task.","metadata":{"loc":{"lines":{"from":98,"to":142}}}}],["3bbe26a1-f991-4685-bdb1-a0514a4751c1",{"pageContent":"Bolding and a color code indicate the best and second-best results for a given task.\n8                                                                                                          Journal of the American Medical Informatics Association, 2024, Vol. 00, No. 0 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":142,"to":144}}}}],["b6930c91-9eb9-4d02-8ea6-810f9f2f4f3d",{"pageContent":"evaluation of multilingual SapBERT. Because we noted that a \nlarge proportion of the evaluation set concerns the names of \nplant and animal species, which are not very relevant to the \nclinical setting these models were developed for, we filtered \nthe XL-BEL test set to exclude these mention types (based on \ntheir UMLS Semantic Types). This enables the evaluation to \nfocus on all the other semantic types, such as clinical disor-\nders, drugs, and procedures.\nOverall, BioLORD-2023-M achieves better results com-\npared to multilingual SapBERT on both German and Span-\nish, the 2 non-English languages supported by both models. \nInterestingly, multilingual SapBERT keeps an edge when it \ncomes to English data, but monolingual models would be bet-\nter suited for this task than a multilingual model.\nIn  summary, the  results of  this  section demonstrate that \nour multilingual BioLORD-2023-M model achieves compa-\nrable performance on multilingual NEL as the multilingual","metadata":{"loc":{"lines":{"from":1,"to":17}}}}],["0bd74ba9-9490-4e66-be17-f205ed177d1a",{"pageContent":"In  summary, the  results of  this  section demonstrate that \nour multilingual BioLORD-2023-M model achieves compa-\nrable performance on multilingual NEL as the multilingual \nSapBERT model while achieving considerably better results \non the English STS and BCR tasks than both the English and \nMultilingual SapBERT on  these datasets. This makes our \nmultilingual model a solid choice for a large range of biomed\n-\nical tasks in the supported languages.\nQualitative assessment in the clinical domain\nTo complement the quantitative evaluation of our model, we \nalso performed a qualitative error analysis to assess the clini-\ncal  validity of  BioLORD-2023 as  a  foundation model for \npractical applications in the future. This is especially impor-\ntant  in  the  clinical domain, where errors can  have serious \nconsequences for patient care and research outcomes.\nTherefore, we conducted a qualitative error analysis of the \nNEL results on  the  PsyTar dataset [59], which contains","metadata":{"loc":{"lines":{"from":15,"to":32}}}}],["92c2cc03-3043-415a-a03f-88a75da241e1",{"pageContent":"consequences for patient care and research outcomes.\nTherefore, we conducted a qualitative error analysis of the \nNEL results on  the  PsyTar dataset [59], which contains \npatient-reported symptoms and adverse reactions related to \npsychological disorders and treatments. We randomly \nselected 200 entity mentions from the test set and manually \nevaluated the  predictions of  BioLORD-2023 and  3  other \nstate-of-the-art models.\nWe present the details of our qualitative error analysis in \nAppendix SE,   where we show that BioLORD-2023 not only \nachieves the highest exact match score by several points but \nalso reduces the number of severe errors by a very large mar-\ngin compared to the other models. Moreover, our Sankey dia-\ngrams show that most of the errors made by BioLORD-2023 \nare shared by the other models, suggesting that model ensem-\nbling would have limited potential.\nWe  attribute these advantages to  the  improved training","metadata":{"loc":{"lines":{"from":30,"to":46}}}}],["e4a40fd9-8089-4fb2-842c-fb509c040116",{"pageContent":"are shared by the other models, suggesting that model ensem-\nbling would have limited potential.\nWe  attribute these advantages to  the  improved training \nstrategy and  data of  BioLORD-2023, which enabled it  to \nlearn more fine-grained and  robust representations of  bio\n-\nmedical concepts and sentences.\nConclusion\nIn this study, we introduced BioLORD-2023, a model offer-\ning state-of-the-art capabilities for clinical STS and concept \nrepresentation.\nThrough the  introduction of  innovative techniques such as \nthe inclusion of LLM-generated definitions in the training data, \na supervised self-distillation phase, a robust model-weights aver-\naging, and a state-of-the-art cross-lingual distillation, we were \nable to train a series of models which confidently demonstrates \nsubstantial performance improvements over their predecessors \nacross a wide range of tasks.\nThese enhancements can have real-world impact, as they \nempower researchers to grasp the global picture of diseases","metadata":{"loc":{"lines":{"from":44,"to":63}}}}],["5ebbd0ce-86d7-4c65-9367-bbc7ea3ab4a6",{"pageContent":"across a wide range of tasks.\nThese enhancements can have real-world impact, as they \nempower researchers to grasp the global picture of diseases \nby tackling the challenges of complex biomedical literature, \nuncover the secrets of genes, proteins, and pathways, thereby \naccelerating the  pace of  biomedical research and drug \ndiscovery.\nMoreover, our models enable a nuanced understanding of \npatient records, extracting meaningful insights that may have \notherwise remained buried. This better comprehension of \nclinical narratives can contribute to more accurate diagnoses, \npersonalized treatment plans, and improved patient \noutcomes.\nTable 3. Performance characteristics of state-of-the-art multilingual biomedical models on STS (Pearson correlation), BCR (Spearman correlation), NEL \n(Top1 Accuracy), and Multilingual NEL (Top1 Accuracy).\nSapBERT\n10\nmSapBERT\n21\nBioLORD-2023-MBioLORD-2023\nSTSMedSTS\n45\n86.085.686.088.3\nMedNLI-S\n46\n90.588.192.192.4\nBIOSSES\n47\n89.390.075.486.1\nSICK\n48","metadata":{"loc":{"lines":{"from":61,"to":91}}}}],["6f42f22a-2e41-43a9-a3fc-734d5d1ea1ee",{"pageContent":"(Top1 Accuracy), and Multilingual NEL (Top1 Accuracy).\nSapBERT\n10\nmSapBERT\n21\nBioLORD-2023-MBioLORD-2023\nSTSMedSTS\n45\n86.085.686.088.3\nMedNLI-S\n46\n90.588.192.192.4\nBIOSSES\n47\n89.390.075.486.1\nSICK\n48\n80.387.089.190.3\nSTS\n49\n81.983.585.187.8\n(average)85.686.885.589.0\nBCREHR-Rel-B\n52\n51.742.464.163.6\nUMNSRS-S\n53\n53.034.260.159.2\nUMNSRS-R\n53\n47.529.654.354.4\nMayoSRS-S\n54\n62.545.274.874.4\n(average)53.737.963.362.9\nNELTwiMed-TW\n56\n48.347.449.347.4\nSMM4H\n57\n43.440.842.346.9\nPsyTAR\n58\n64.851.563.366.3\nCADEC\n59\n40.446.847.047.4\nTwiMed-PM\n56\n70.163.967.469.4\n(average)53.450.453.955.5\nMNELGerman XLB\n21\nN/A51.557.7N/A\nSpanish XLB\n21\nN/A52.753.1N/A\nEnglish XLB\n21\nN/A78.273.1N/A\n(average)N/A58.159.4N/A\nBolding indicates the best results among multilingual models for a given task. (English-only models are only provided for comparison purposes.)","metadata":{"loc":{"lines":{"from":75,"to":136}}}}],["b107fe56-7fb6-4848-bd11-8646dc6e2fba",{"pageContent":"English XLB\n21\nN/A78.273.1N/A\n(average)N/A58.159.4N/A\nBolding indicates the best results among multilingual models for a given task. (English-only models are only provided for comparison purposes.)\nJournal of the American Medical Informatics Association, 2024, Vol. 00, No. 0                                                                                                           9 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":132,"to":138}}}}],["c556c58a-80a8-4b12-895b-b826f2906a4d",{"pageContent":"Limitations and future work\nWhile our work showcases an impressive improvement over \nthe previous state of the art, it is not without limitations. One \nsuch limitation is the bound of its knowledge, which is con-\nstrained by the knowledge contained in the knowledge graphs \nused to prompt the language model.\nMany entities in the knowledge graph contain few pieces \nof information, and this is particularly the case for organisms \nand species, making BioLORD models inadequate to differ-\nentiate between such entities, as they acquire very similar rep-\nresentations. Another limitation is  that knowledge graphs \ntrail the literature and might not include all new pieces of \nknowledge mentioned in the published biomedical papers.\nTo address this problem, we foresee a future version of this \nmodel which would rely on a combination of the knowledge \ngraph information and of the recent biomedical literature to \nprompt LLMs before generating definitions, thereby includ-","metadata":{"loc":{"lines":{"from":1,"to":17}}}}],["3db850e8-d3d3-4b58-b272-150b5e2a93a3",{"pageContent":"model which would rely on a combination of the knowledge \ngraph information and of the recent biomedical literature to \nprompt LLMs before generating definitions, thereby includ-\ning even more recent and relevant information, and helping \ncreate a  more precise definitions for  rare or  very specific \nconcepts.\nThe retrieval of the relevant documents to include in the \nprompt will already benefit from our state-of-the-art BioL-\nORD-2023 model. We hope to study the impact of grounding \ndocument retrieval on the generated definitions in an upcom-\ning study.\nWe  also  foresee future versions of  BioLORD or  similar \nsemantic models making use of the larger STS models that \nare starting to become available. While most of the successful \nmodels remain closed sourced so far and can therefore not be \nfreely finetuned for the biomedical domain, new and larger \nmodels are  expected to  be  open-sourced as  time goes by. \nApplying the  self-distillation phase of  BioLORD to  these","metadata":{"loc":{"lines":{"from":15,"to":32}}}}],["707b9246-6b78-41f5-9ea7-dc8ba0cbfdba",{"pageContent":"freely finetuned for the biomedical domain, new and larger \nmodels are  expected to  be  open-sourced as  time goes by. \nApplying the  self-distillation phase of  BioLORD to  these \nmodels could prove an efficient way to leverage them.\nAcknowledgments\nThis work would not have been possible without the joint \nfinancial support of  the  Vlaams Agentschap Innoveren & \nOndernemen (VLAIO) and the RADar innovation center of \nthe AZ Delta hospital group, through their ambitious joint \nventure in  the  Advanced Data-Aided Medicine project \n(ADAM).\nI would, of course, like to extend special thanks to Karel \nD’Oosterlinck, Alfiya Khabibullina, Beatrice Portelli, Simone \nScarboro, Peter De Jaeger, and other individuals who helped \nme make progress along the way toward this journal publica-\ntion, often in  the  form of  joint conference or  workshop \npublications.\nA particular thanks is also extended to the team maintain-\ning and developing GPULab, the machine learning infrastruc-","metadata":{"loc":{"lines":{"from":30,"to":48}}}}],["95880f71-df90-4a32-99fc-eaf317d4dc44",{"pageContent":"tion, often in  the  form of  joint conference or  workshop \npublications.\nA particular thanks is also extended to the team maintain-\ning and developing GPULab, the machine learning infrastruc-\nture for AI computing built in collaboration between UGent, \nUAntwerpen, and the imec research and development center.\nFinally, I would also like to thank my co-supervisors, Tho-\nmas  Demeester and  Kris Demuynck, for  their support and \nconstructive advice during the ideation process, and all along \nthe development of this project up to this very article.\nAuthor contributions\nWe, the  authors of  this work, Franc ̧ois Remy, Kris \nDemuynck, and Thomas Demeester, collectively contributed \nto every stage of this project in accordance with the ICMJE \nguidelines for authorship. In the initial phase, we collabora-\ntively conceived and designed the project goals, agenda, and \nmethodologies. Subsequently, Franc ̧ois  Remy assumed the \nrole of lead researcher, spearheading the execution of experi-","metadata":{"loc":{"lines":{"from":45,"to":62}}}}],["d014ab0b-5253-4383-b9ea-5691f3a683fd",{"pageContent":"tively conceived and designed the project goals, agenda, and \nmethodologies. Subsequently, Franc ̧ois  Remy assumed the \nrole of lead researcher, spearheading the execution of experi-\nments, while Kris Demuynck and  Thomas Demeester pro-\nvided oversight and guidance in a supervisory capacity, with \nbiweekly meetings. Throughout the  project’s evolution, all \nauthors actively participated in  shaping refinements and \nimprovements. We  confirm that all  authors reviewed and \napproved each revision of this publication.\nSupplementary material\nSupplementary material is available at Journal of the Ameri-\ncan Medical Informatics Association online.\nFunding\nThis work was supported by the “ADAM” grant of VLAIO \nO&O (HBC.2020.3234).\nConflicts of interest\nNone declared.\nData availability\nOur training datasets (BioLORD, AGCT) and models (BioL-\nORD-2023, BioLORD-2023-M) are all available for down-\nload on HuggingFace.\nReferences\n1.0   Houssein EH, Rehab EM, Abdelmgeid AA. Machine learning tech-","metadata":{"loc":{"lines":{"from":60,"to":82}}}}],["de4f47c7-4ceb-43c1-b38f-bcdda102faa3",{"pageContent":"ORD-2023, BioLORD-2023-M) are all available for down-\nload on HuggingFace.\nReferences\n1.0   Houssein EH, Rehab EM, Abdelmgeid AA. Machine learning tech-\nniques for biomedical natural language processing: a comprehen-\nsive review. IEEE Access. 2021;9:140628-140653.\n2.0   Shi J, Yuan Z, Guo W, Ma C, Chen J, Zhang M. Knowledge- \ngraph-enabled biomedical entity linking: a  survey. World Wide \nWeb. 2023;26(5):2593-2622.\n3.0   Pan S, Luo L, Wang Y, Chen C, Wang J, Wu X. Unifying large lan-\nguage models and knowledge graphs: a roadmap. arXiv. June 14, \n2023, preprint: not peer reviewed.\n4.0   Satvik G, Shivam P, Somya G. Navigating healthcare insights: a \nbirds eye view of explainability with knowledge graphs. In: 2023 \nIEEE Sixth International Conference on Artificial Intelligence and \nKnowledge Engineering (AIKE). 2023:54-61.\n5.0   Lin X, Dai L, Zhou Y, et al. Comprehensive evaluation of deep \nand  graph learning on  drug-drug interactions prediction. Brief \nBioinform. 2023;24(4):1-20.","metadata":{"loc":{"lines":{"from":79,"to":97}}}}],["8420273e-e906-4284-bb1b-f44f9e814b00",{"pageContent":"5.0   Lin X, Dai L, Zhou Y, et al. Comprehensive evaluation of deep \nand  graph learning on  drug-drug interactions prediction. Brief \nBioinform. 2023;24(4):1-20.\n6.0   Wang B, Xie Q, Pei J, et al. Pre-trained language models in bio-\nmedical domain: a  systematic survey. ACM Comput Surv. \n2023;56(3):1-52.\n7.0   Hu L, Liu Z, Zhao Z, Hou L, Nie L, Li J. A survey of knowledge \nenhanced pre-trained language models. IEEE Tran Knowl Data \nEng.    2023. https://doi.org/10.1109/TKDE.2023.3310002\n8.0   Feng Z, Ma W, Yu W, et al. Trends in integration of knowledge \nand large language models: a survey and taxonomy of methods, \nbenchmarks, and applications. arXiv. November 10, 2023, pre\n-\nprint: not peer reviewed.\n9.0   Sung M, Jeon H, Lee J, Kang J. Biomedical entity representations \nwith synonym marginalization. In: Proceedings of the 58th Annual \nMeeting of  the  Association for  Computational Linguistics, July \n2020:3641-3650.","metadata":{"loc":{"lines":{"from":95,"to":112}}}}],["89f3fafb-b906-4e0f-80c7-4ab9ed951f68",{"pageContent":"with synonym marginalization. In: Proceedings of the 58th Annual \nMeeting of  the  Association for  Computational Linguistics, July \n2020:3641-3650.\n10. Liu  F,  Shareghi E,  Meng Z,  Basaldella M,  Collier N.  Self- \nalignment pretraining for  biomedical entity representations. In: \nProceedings of  the  2021 Conference of  the  North American \n10                                                                                                        Journal of the American Medical Informatics Association, 2024, Vol. 00, No. 0 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":110,"to":117}}}}],["40f5e5f8-75f2-4bcd-8365-533308f22ae5",{"pageContent":"Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies, June 2021:4228-4238.\n11. Remy F, Demuynck K, Demeester T. BioLORD: learning ontologi-\ncal representations from definitions for biomedical concepts and \ntheir textual descriptions. In: Findings of the Association for Com-\nputational Linguistics: EMNLP 2022, December 2022: \n1454-1465.\n12. Devlin J, Chang M-W, Lee K, Toutanova K. BERT: pre-training of \ndeep bidirectional transformers for  language understanding. In: \nProceedings of the 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics: Human Lan-\nguage Technologies, 2019:4171-4186.\n13. Lewis P, Perez E, Piktus A, et al. Retrieval-augmented generation \nfor knowledge-intensive NLP tasks. In: Proceedings of the 34th \nInternational Conference on Neural Information Processing Sys\n-\ntems, December 2020:9459-9474.\n14. Kim J, Choi S, Amplayo RK, Hwang SW. Retrieval-augmented","metadata":{"loc":{"lines":{"from":1,"to":18}}}}],["e5bef094-cc2b-4f52-8e04-1f7b103b2574",{"pageContent":"International Conference on Neural Information Processing Sys\n-\ntems, December 2020:9459-9474.\n14. Kim J, Choi S, Amplayo RK, Hwang SW. Retrieval-augmented \ncontrollable review generation. In: Proceedings of the 28th Inter-\nnational Conference on  Computational Linguistics, December \n2020:2284-2295.\n15. Ouyang L, Wu J, Jiang X, et al. Training language models to fol-\nlow instructions with human feedback. Adv Neural Inform Proc \nSyst.    2022;35:27730-27744.\n16. Bodenreider O. The Unified Medical Language System (UMLS): \nintegrating biomedical terminology. Nucleic Acids Res. 2004;32 \n(Database issue):D267-D270.\n17. Cot\n�\ne  RA,  Robboy S.  Progress in  medical information manage-\nment. Systematized nomenclature of  medicine (SNOMED). \nJAMA. 1980;243(8):756-762.\n18. Remy F, Demuynck K, Demeester T. Automatic Glossary of Clini-\ncal Terminology: a large-scale dictionary of biomedical definitions \ngenerated from ontological knowledge. In: The 22nd Workshop","metadata":{"loc":{"lines":{"from":15,"to":35}}}}],["6319c53e-72b1-4022-a701-e151091a5869",{"pageContent":"18. Remy F, Demuynck K, Demeester T. Automatic Glossary of Clini-\ncal Terminology: a large-scale dictionary of biomedical definitions \ngenerated from ontological knowledge. In: The 22nd Workshop \non Biomedical Natural Language Processing and BioNLP Shared \nTasks, July 2023:265-272.\n19. Reimers N,  Gurevych I.  Making monolingual sentence embed-\ndings multilingual using knowledge distillation. In: Proceedings of \nthe 2020 Conference on Empirical Methods in Natural Language \nProcessing, November 2020:4512-4525.\n20. Feng F,  Yang Y,  Cer  D,  Arivazhagan N,  Wang W.  Language- \nagnostic BERT sentence embedding. In: Proceedings of the 60th \nAnnual Meeting of the Association for Computational Linguistics, \nMay 2022:878-891.\n21. Liu  F,  Vuli\n�\nc  I,  Korhonen A,  Collier N.  Learning domain- \nspecialised representations for cross-lingual biomedical entity link-\ning. In: Proceedings of the 59th Annual Meeting of the Association","metadata":{"loc":{"lines":{"from":33,"to":50}}}}],["effa9513-22af-4365-ba50-8ccd57a62c1a",{"pageContent":"�\nc  I,  Korhonen A,  Collier N.  Learning domain- \nspecialised representations for cross-lingual biomedical entity link-\ning. In: Proceedings of the 59th Annual Meeting of the Association \nfor  Computational Linguistics and  the  11th International Joint \nConference on  Natural Language Processing, vol. 2,  August \n2021:565-574.\n22. Cui H, Lu J, Wang S, et al. A survey on knowledge graphs for \nhealthcare: resources, applications, and promises. arXiv. August \n23, 2023, preprint: not peer reviewed.\n23. Yang X, Chen A, PourNejatian N, et al. A large language model \nfor electronic health records. NPJ Digit Med. 2022;5(1):194.\n24. Singhal K, Azizi S, Tu T, et al. Large language models encode clini-\ncal knowledge. Nature. 2023;620(7972):172-180.\n25. Lee P, Bubeck S, Petro J. Benefits, limits, and risks of GPT-4 as \nan  AI  chatbot for  medicine. N  Engl J  Med. 2023;388 \n(13):1233-1239.\n26. Venkatesh KP, Raza MM, Kvedar JC. Automating the overbur-","metadata":{"loc":{"lines":{"from":47,"to":64}}}}],["e6d630f4-39f1-494c-aae4-86f2a35cc18f",{"pageContent":"an  AI  chatbot for  medicine. N  Engl J  Med. 2023;388 \n(13):1233-1239.\n26. Venkatesh KP, Raza MM, Kvedar JC. Automating the overbur-\ndened clinical coding system: challenges and next steps. NPJ Digit \nMed. 2023;36(1):16.\n27. Wu C,  Lei  J,  Zheng Q,  et  al.  Can GPT-4V(ision) serve \nmedical applications? Case studies on  GPT-4V for  multimodal \nmedical diagnosis. arXiv. October 17, 2023, preprint: not peer \nreviewed.\n28. Yan Z,  Zhang K,  Zhou R,  He  L,  Li  X,  Sun  L.  Multimodal \nChatGPT for medical applications: an experimental study of GPT- \n4V. arXiv. October 29, 2023, preprint: not peer reviewed.\n29. Jin Q, Wang Z, Floudas CS, Sun J, Lu Z. Matching patients to clin-\nical trials with large language models. arXiv. July 28, 2023, pre-\nprint: not peer reviewed.\n30. Taylor R, Kardas M, Cucurull G, et al. Galactica: a large language \nmodel for science. arXiv. November 16, 2022, preprint: not peer \nreviewed.\n31. Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT: large language","metadata":{"loc":{"lines":{"from":62,"to":80}}}}],["3df214e0-ad42-4118-b602-2f1ced4e8b6c",{"pageContent":"model for science. arXiv. November 16, 2022, preprint: not peer \nreviewed.\n31. Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT: large language \nmodels finetuned with diverse medical data and  comprehensive \nevaluation. arXiv. June 16, 2023, preprint: not peer reviewed.\n32. Bolton E,  et  al.  Stanford CRFM introduces PubMedGPT 2.7B. \nStanford University, 2022. Accessed May 2023. https://hai.stan-\nford.edu/news/stanford-crfm-introduces-pubmedgpt-27b \n33. Luo R, Sun L, Xia Y, et al. BioGPT: generative pre-trained trans-\nformer for biomedical text  generation and mining. Brief Bioin-\nform. 2022;23(6):bbac409.\n34. OpenAI. GPT-4 technical report. arXiv. March 15, 2023, preprint: \nnot peer reviewed.\n35. Oord AV, Li Y, Vinyals O. Representation learning with contras-\ntive predictive coding. arXiv. July  10,  2018, preprint: not  peer \nreviewed.\n36. Remy F, Scaboro S, Portelli B. Boosting adverse drug event nor-\nmalization on social media: general-purpose model initialization","metadata":{"loc":{"lines":{"from":78,"to":95}}}}],["39105e1c-f996-4818-abaf-cd7ec2424276",{"pageContent":"reviewed.\n36. Remy F, Scaboro S, Portelli B. Boosting adverse drug event nor-\nmalization on social media: general-purpose model initialization \nand biomedical semantic text similarity benefit zero-shot linking in \ninformal contexts. In: Proceedings of the Eleventh International \nWorkshop on  Natural Language Processing for  Social Media, \nNovember 1, 2023:47-52.\n37. Reimers N,  Gurevych I.  Sentence-BERT: sentence embeddings \nusing siamese BERT-networks. In: Proceedings of the 2019 Con\n-\nference on Empirical Methods in Natural Language Processing, \nNovember 2019:3982-3992.\n38. Ribeiro J, Melo FS, Dias J. Multi-task learning and catastrophic \nforgetting in continual reinforcement learning. EPiC Ser Comput. \n2019;65:163-175.\n39. He T, Liu J, Cho K, et al. Analyzing the forgetting problem in \npretrain-finetuning of open-domain dialogue response models. In: \nProceedings of the 16th Conference of the European Chapter of \nthe Association for Computational Linguistics, May \n2021:1121-1133.","metadata":{"loc":{"lines":{"from":93,"to":112}}}}],["206c5683-2947-4c5c-a84d-fccc9240b9fc",{"pageContent":"pretrain-finetuning of open-domain dialogue response models. In: \nProceedings of the 16th Conference of the European Chapter of \nthe Association for Computational Linguistics, May \n2021:1121-1133.\n40. Gao T, Yao X, Chen D. SimCSE: simple contrastive learning of \nsentence embeddings. In: Proceedings of the 2021 Conference on \nEmpirical Methods in Natural Language Processing, November \n2021:6894-6910.\n41. Li B, Zhou H, He J, Wang M, Yang Y, Li L. On the sentence \nembeddings from pre-trained language models. In: Proceedings of \nthe 2020 Conference on Empirical Methods in Natural Language \nProcessing, November 2020:9119-9130.\n42. Ethayarajh K. How contextual are contextualized word represen-\ntations? comparing the  geometry of  BERT, ELMo, and  GPT-2 \nembeddings. In: Proceedings of the 2019 Conference on Empirical \nMethods in Natural Language Processing, November 2019:55-65.\n43. Wortsman M, Ilharco G, Gadre SY, et al. Model soups: averaging","metadata":{"loc":{"lines":{"from":109,"to":125}}}}],["79230032-51bf-4ee9-8a2e-42e0536f3ce4",{"pageContent":"embeddings. In: Proceedings of the 2019 Conference on Empirical \nMethods in Natural Language Processing, November 2019:55-65.\n43. Wortsman M, Ilharco G, Gadre SY, et al. Model soups: averaging \nweights of multiple fine-tuned models improves accuracy without \nincreasing inference time. In: International Conference on \nMachine Learning, vol. 162, 2022:23965-23998.\n44. Remy F, De Jaeger P, Demuynck K. Taming large lexicons: trans-\nlating clinical text  using medical ontologies and  sentence tem-\nplates. In: EmP: 1st  RADar Conference on  Engineer Meets \nPhysician, 2022:1-5.\n45. Wang Y, Afzal N, Fu  S,  et  al. MedSTS: a  resource for clinical \nsemantic textual similarity. Lang Resourc Eval. 2020;54(1):57-72.\n46. Romanov A, Shivade C. Lessons from natural language inference \nin the clinical domain. In: Proceedings of the 2018 Conference on \nEmpirical Methods in Natural Language Processing, November \n2018, 1586-1596.\n47. Sogancioglu G, \n€\nOzt€urk H, \n€","metadata":{"loc":{"lines":{"from":123,"to":142}}}}],["603f0c40-a853-4a76-8261-3c403c3f0ed9",{"pageContent":"in the clinical domain. In: Proceedings of the 2018 Conference on \nEmpirical Methods in Natural Language Processing, November \n2018, 1586-1596.\n47. Sogancioglu G, \n€\nOzt€urk H, \n€\nOzg€ur A. BIOSSES: a semantic sentence \nsimilarity estimation system for the biomedical domain. Bioinfor-\nmatics. 2017;33(14):i49-i58.\n48. Marelli M, Menini S, Baroni M, Bentivogli L, Bernardi R, Zampar-\nelli  R.  A  SICK cure for  the  evaluation of  compositional \nJournal of the American Medical Informatics Association, 2024, Vol. 00, No. 0                                                                                                        11 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":136,"to":149}}}}],["465f5817-2aa0-435d-8ada-8e3ec09c746a",{"pageContent":"distributional semantic models. In: Proceedings of the Ninth Inter-\nnational Conference on Language Resources and Evaluation, May \n2014:216-233.\n49. Cer D, Diab M, Agirre E, Lopez-Gazpio I, Specia L. SemEval-2017 \nTask 1: semantic textual similarity multilingual and crosslingual \nfocused evaluation. In: Proceedings of  the  11th International \nWorkshop on Semantic Evaluation, August 2017:1-14.\n50. Ofer D,  Linial M.  Automated annotation of  disease subtypes. \nmedRxiv. September 25, 2023), preprint: not peer reviewed.\n51. Kalyan KS, Sangeetha S. Hybrid approach to measure semantic \nrelatedness in biomedical concepts. arXiv. January 25, 2021, pre-\nprint: not peer reviewed.\n52. Schulz C, Levy-Kramer J, Van Assel C, Kepes M, Hammerla N. \nBiomedical concept relatedness—a large EHR-based benchmark. \nIn: Proceedings of the 28th International Conference on Computa-\ntional Linguistics, December 2020:6565-6575.\n53. Pakhomov SV, McInnes B, Adam T, Liu Y, Pedersen T, Melton","metadata":{"loc":{"lines":{"from":1,"to":17}}}}],["1fac78e5-9613-4197-bbda-b706eec95ca8",{"pageContent":"In: Proceedings of the 28th International Conference on Computa-\ntional Linguistics, December 2020:6565-6575.\n53. Pakhomov SV, McInnes B, Adam T, Liu Y, Pedersen T, Melton \nGB. Semantic similarity and relatedness between clinical terms: an \nexperimental study. AMIA Annu Symp. Proc. 2010;2010:572.\n54. Pakhomov SV, Pedersen T, McInnes B, Melton GB, Ruggieri A, \nChute CG. Towards a framework for developing semantic related-\nness reference standards. J Biomed Inform. 2011;44(2):251-265.\n55. Portelli B, Scaboro S, Santus E, Sedghamiz H, Chersoni E, Serra G. \nGeneralizing over long tail concepts for medical term \nnormalization. In: Proceedings of the 2022 Conference on Empiri-\ncal  Methods in  Natural Language Processing, December \n2022:8580-8591.\n56. Alvaro N, Miyao Y, Collier N. TwiMed: twitter and PubMed com-\nparable corpus of drugs, diseases, symptoms, and their relations. \nJMIR Public Health Surveill. 2017;3(2):e24.\n57. Gonzalez-Hernandez G, Klein AZ, Flores I, et al. Overview of the","metadata":{"loc":{"lines":{"from":15,"to":31}}}}],["5e80e1f0-df32-49b5-9799-f483b656159a",{"pageContent":"parable corpus of drugs, diseases, symptoms, and their relations. \nJMIR Public Health Surveill. 2017;3(2):e24.\n57. Gonzalez-Hernandez G, Klein AZ, Flores I, et al. Overview of the \nFifth Social Media Mining for  Health Applications (#SMM4H) \nShared Tasks at COLING 2020. In: Proceedings of the Fifth Social \nMedia Mining for Health Applications Workshop & Shared Task. \nAssociation for Computational Linguistics, December 2020:27-36.\n58. Zolnoori M, Fung KW, Patrick TB, et al. The PsyTAR dataset: \nFrom patients generated narratives to a corpus of adverse drug \nevents and  effectiveness of  psychiatric medications. Data Brief. \n2019;24:103838.\n59. Karimi S, Metke-Jimenez A, Kemp M, Wang C. Cadec: a corpus of \nadverse drug event annotations. J Biomed Inform. 2015;55:73-81.\n60. Jin Q, Kim W, Chen Q, et al. MedCPT: contrastive pre-trained \ntransformers with large-scale PubMed search logs for zero-shot \nbiomedical information retrieval. Bioinformatics. 2023;39(11): \nbtad651.","metadata":{"loc":{"lines":{"from":29,"to":45}}}}],["69221acb-557a-435e-a672-318cbf2395f5",{"pageContent":"transformers with large-scale PubMed search logs for zero-shot \nbiomedical information retrieval. Bioinformatics. 2023;39(11): \nbtad651.\n61. Mao Y, Fung KW. Use of word and graph embedding to measure \nsemantic relatedness between Unified Medical Language System \nconcepts. J Am Med Inform Assoc. 2020;27(10):1538-1546.\n12                                                                                                        Journal of the American Medical Informatics Association, 2024, Vol. 00, No. 0 \nDownloaded from https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae029/7614965 by guest on 28 February 2024","metadata":{"loc":{"lines":{"from":43,"to":50}}}}]],{"0":"8b09e4e1-9241-43a5-bc39-d4d0108431c0","1":"bae2cbd2-8c31-4c2f-9e51-07ba017ba271","2":"daa7b584-b1e4-467e-a2e8-bdd832aef1bb","3":"7f9c62f8-e11f-4c14-ac82-a2fd99b05660","4":"9213c17b-a9b1-445c-ba8a-38744ee7679d","5":"650aa42c-5fd8-43b5-9970-94cb832a707e","6":"c1190eff-2b78-4e46-b018-993a66dec442","7":"c747dcfd-46a1-4179-8f89-906899475052","8":"aef9560c-64de-4f95-88b2-f55dd7bdbb71","9":"bbe94736-fb70-4a31-98f6-0b8123217883","10":"a87ce33a-c0f2-43c0-801f-4eea901333ae","11":"4d7ae67e-93d0-4c4d-aea9-bb0478543416","12":"7ad20a0c-c384-4133-9d4b-2006ebb90589","13":"595298a5-e99c-4de0-90a6-145e6a0cf6ae","14":"d9d38551-8864-4961-b6d2-f59f39fafaf6","15":"af9eb48e-2f92-4abf-96bf-9dfd6265d33f","16":"fe1c9fe5-61d4-44c5-96bf-44a68a15f2a4","17":"d25db771-c712-4b36-8cca-c3a0fe95d609","18":"085ddfa8-9562-4f42-8bf4-9b90f75ed456","19":"e96f02b8-92f0-46e1-9d76-830338321f99","20":"2e380b54-1d25-4ebf-b601-1bcfe1377989","21":"80130cee-0987-48ef-8981-5b60d1d0223a","22":"4112e071-953e-4248-be0b-f550733e3c44","23":"d6486547-d836-46db-9a50-55062257ba59","24":"b5d0da3d-a001-4fae-a812-54b9c1cea21d","25":"8330d336-1642-46e8-97f6-ec1b9c9075c1","26":"ec822c0e-cc31-4c0f-9e27-aee40dafb602","27":"6b39ba05-542d-4c74-9233-665641d66e54","28":"3586cce0-7071-41d9-9471-bf2eb76a6912","29":"2799f9b9-da49-40ae-9bd4-2c4b82f8b25a","30":"56e8e511-e6b4-4240-87aa-d16e8455cffb","31":"b84e64d6-bf25-4288-bf0c-81046136aa50","32":"6aac7851-5cf5-4b6f-a3ef-de4292a9921b","33":"5c2bf022-d571-4093-a1a3-5affece562a2","34":"39ef623a-12e2-47db-a31a-82c99342da69","35":"05d70513-4f23-4a24-a8b7-fb78ed3a88f0","36":"6cdd3b9a-acbf-4013-861e-83eb50255900","37":"e9a8d513-becb-4df6-9f77-0555b361f987","38":"a1cf794b-47b3-4e36-b0a5-ec9ed8881f87","39":"c5f168f4-b787-4f62-95fc-05c99e3e280c","40":"c119dc5d-df4c-4085-8b8d-2ed3db2ce84e","41":"7824f17d-3cae-42d0-a2e4-6de743016d58","42":"5e59f880-030e-44a2-b1ee-885d432dbafd","43":"b600bec5-81eb-4e79-9655-ffc3c4b6f203","44":"b62c0bdf-8e57-4011-8fa8-8c1475d0eaa8","45":"b88fbc84-ba91-4c49-85a1-8057ab279388","46":"96adeb46-5561-4e46-a3e8-fa5e9775f451","47":"274100f2-da34-40c5-a36f-784d6125b7f0","48":"87f992f1-a8d4-4905-8be6-951c6db9dd69","49":"3d7e6df8-e31a-4e8a-bddd-85d54268150f","50":"f612d507-e20c-4356-8d56-1740e96a7913","51":"c609e2fc-d336-4d00-bff2-aa925dfa2b86","52":"3cff12bf-559e-4de1-953b-ab366fa76a1a","53":"e38fc93e-503b-4631-b053-f0aef57901d5","54":"010cd487-680f-49e6-808e-0ec2c16d13b0","55":"57a5d49f-7c1e-46dc-8697-51e9f1721bff","56":"3bbe26a1-f991-4685-bdb1-a0514a4751c1","57":"b6930c91-9eb9-4d02-8ea6-810f9f2f4f3d","58":"0bd74ba9-9490-4e66-be17-f205ed177d1a","59":"92c2cc03-3043-415a-a03f-88a75da241e1","60":"e4a40fd9-8089-4fb2-842c-fb509c040116","61":"5ebbd0ce-86d7-4c65-9367-bbc7ea3ab4a6","62":"6f42f22a-2e41-43a9-a3fc-734d5d1ea1ee","63":"b107fe56-7fb6-4848-bd11-8646dc6e2fba","64":"c556c58a-80a8-4b12-895b-b826f2906a4d","65":"3db850e8-d3d3-4b58-b272-150b5e2a93a3","66":"707b9246-6b78-41f5-9ea7-dc8ba0cbfdba","67":"95880f71-df90-4a32-99fc-eaf317d4dc44","68":"d014ab0b-5253-4383-b9ea-5691f3a683fd","69":"de4f47c7-4ceb-43c1-b38f-bcdda102faa3","70":"8420273e-e906-4284-bb1b-f44f9e814b00","71":"89f3fafb-b906-4e0f-80c7-4ab9ed951f68","72":"40f5e5f8-75f2-4bcd-8365-533308f22ae5","73":"e5bef094-cc2b-4f52-8e04-1f7b103b2574","74":"6319c53e-72b1-4022-a701-e151091a5869","75":"effa9513-22af-4365-ba50-8ccd57a62c1a","76":"e6d630f4-39f1-494c-aae4-86f2a35cc18f","77":"3df214e0-ad42-4118-b602-2f1ced4e8b6c","78":"39105e1c-f996-4818-abaf-cd7ec2424276","79":"206c5683-2947-4c5c-a84d-fccc9240b9fc","80":"79230032-51bf-4ee9-8a2e-42e0536f3ce4","81":"603f0c40-a853-4a76-8261-3c403c3f0ed9","82":"465f5817-2aa0-435d-8ada-8e3ec09c746a","83":"1fac78e5-9613-4197-bbda-b706eec95ca8","84":"5e80e1f0-df32-49b5-9799-f483b656159a","85":"69221acb-557a-435e-a672-318cbf2395f5"}]